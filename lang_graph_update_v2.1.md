# LangGraph 0.6.6 ì±—ë´‡ ê°œì„  ê°€ì´ë“œ (ìˆ˜ì •íŒ)

## ðŸ“‹ í˜„ìž¬ ìƒíƒœ ë¶„ì„ ë° ê°œì„  ì§€ì‹œì‚¬í•­

### âš ï¸ í•µì‹¬ ê·œì¹™ (MUST FOLLOW)

1. **ë™ì‹œì„± ì•ˆì „ì„±**: ëª¨ë“  State ìˆ˜ì •ì€ thread-safeí•´ì•¼ í•¨
2. **ìŠ¤íŠ¸ë¦¬ë° ìˆœì„œ**: WebSocket ë©”ì‹œì§€ëŠ” ë…¼ë¦¬ì  ìˆœì„œ ìœ ì§€ í•„ìˆ˜
3. **ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš©**: í•œ ì—ì´ì „íŠ¸ ì‹¤íŒ¨ê°€ ì „ì²´ ì¤‘ë‹¨ìœ¼ë¡œ ì´ì–´ì§€ë©´ ì•ˆë¨
4. **ë©”ëª¨ë¦¬ ì œí•œ**: ë™ì‹œ ì‹¤í–‰ ì—ì´ì „íŠ¸ëŠ” ìµœëŒ€ 3ê°œë¡œ ì œí•œ
5. **Checkpointer í˜¸í™˜**: SQLite ì‚¬ìš© ì‹œ WAL ëª¨ë“œ í•„ìˆ˜

---

## ðŸš€ Phase 0: ê¸°ì´ˆ ì•ˆì „ìž¥ì¹˜ êµ¬í˜„ [ìµœìš°ì„ ]

### 0.1 State ë™ì‹œì„± ë³´í˜¸

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**ìƒˆ íŒŒì¼: `backend/src/core/concurrency.py`**

```python
import asyncio
from threading import Lock
from typing import Dict, Any
from contextlib import contextmanager
import copy

class ThreadSafeState:
    """Thread-safe State wrapper for parallel execution"""
    
    def __init__(self, state: Dict[str, Any]):
        self._state = state
        self._lock = asyncio.Lock()
        self._write_locks = {}  # Per-agent write locks
    
    async def get(self, key: str, default=None):
        """Thread-safe read"""
        async with self._lock:
            return copy.deepcopy(self._state.get(key, default))
    
    async def update_results(self, agent_name: str, data: Dict):
        """Thread-safe results update"""
        async with self._lock:
            if "results" not in self._state:
                self._state["results"] = {}
            self._state["results"][agent_name] = data
            
            # Update progress
            if "progress" not in self._state:
                self._state["progress"] = []
            self._state["progress"].append({
                "agent": agent_name,
                "timestamp": datetime.now().isoformat(),
                "action": "completed"
            })
    
    async def get_snapshot(self) -> Dict:
        """Get complete state snapshot"""
        async with self._lock:
            return copy.deepcopy(self._state)
    
    def to_dict(self) -> Dict:
        """Convert back to regular dict for graph compatibility"""
        return self._state
```

### 0.2 Checkpointer ìµœì í™”

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**íŒŒì¼: `backend/src/core/graph.py` ìˆ˜ì •**

```python
def create_optimized_checkpointer(use_sqlite: bool = False):
    """Create optimized checkpointer with concurrency support"""
    if use_sqlite and SqliteSaver:
        db_path = os.path.join(os.path.dirname(__file__), "..", "..", "checkpoints.db")
        
        # Enable WAL mode for concurrent access
        import sqlite3
        conn = sqlite3.connect(db_path)
        conn.execute("PRAGMA journal_mode=WAL")
        conn.execute("PRAGMA synchronous=NORMAL")
        conn.close()
        
        return SqliteSaver.from_conn_string(f"sqlite:///{db_path}")
    else:
        # Consider Redis for production
        return MemorySaver()
```

### 0.3 WebSocket ìŠ¤íŠ¸ë¦¬ë° ì¡°ì •ìž

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**ìƒˆ íŒŒì¼: `backend/src/core/streaming.py`**

```python
import asyncio
from typing import Dict, List, Any
from collections import OrderedDict

class StreamingCoordinator:
    """Coordinate streaming messages during parallel execution"""
    
    def __init__(self):
        self.message_queues: Dict[str, asyncio.Queue] = {}
        self.agent_order = []
        self.completed_agents = set()
    
    async def register_agent(self, agent_name: str):
        """Register an agent for streaming coordination"""
        if agent_name not in self.message_queues:
            self.message_queues[agent_name] = asyncio.Queue()
    
    async def queue_message(self, agent_name: str, message: Dict):
        """Queue a message from an agent"""
        if agent_name in self.message_queues:
            await self.message_queues[agent_name].put(message)
    
    async def stream_in_order(self, websocket, client_id: str, parallel_groups: List[List[str]]):
        """Stream messages maintaining logical order"""
        for group in parallel_groups:
            # Collect messages from parallel agents
            group_messages = OrderedDict()
            
            # Start collectors for each agent in group
            tasks = []
            for agent in group:
                tasks.append(self._collect_agent_messages(agent, group_messages))
            
            # Wait for all agents in group
            await asyncio.gather(*tasks)
            
            # Stream collected messages in order
            for agent in group:
                if agent in group_messages:
                    for message in group_messages[agent]:
                        await websocket.send_json({
                            "type": "agent_output",
                            "agent": agent,
                            "message": message,
                            "timestamp": datetime.now().isoformat()
                        })
    
    async def _collect_agent_messages(self, agent_name: str, storage: OrderedDict):
        """Collect all messages from an agent"""
        storage[agent_name] = []
        queue = self.message_queues.get(agent_name)
        
        if queue:
            while True:
                try:
                    message = await asyncio.wait_for(queue.get(), timeout=0.1)
                    storage[agent_name].append(message)
                except asyncio.TimeoutError:
                    break
```

---

## ðŸš€ Phase 1: Tool ì‹¤í–‰ ë©”ì»¤ë‹ˆì¦˜ ê°œì„  [ë†’ìŒ]

### 1.1 LLM ê¸°ë°˜ Tool ì‹¤í–‰ êµ¬í˜„

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**íŒŒì¼: `backend/src/agents/analytics.py` ìˆ˜ì •**

```python
from langchain_core.messages import ToolMessage, AIMessage
from langgraph.prebuilt import create_react_agent
from typing import List, Dict, Any

async def analytics_agent_with_llm_tools(state: AgentState) -> dict:
    """Enhanced Analytics agent with LLM-based tool execution"""
    
    # Thread-safe state wrapper
    safe_state = ThreadSafeState(state)
    
    # Initialize LLM
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    # Define tools
    tools = [
        query_performance_data,
        analyze_sales_trend,
        calculate_kpis,
        predict_sales_trend
    ]
    
    # Create ReAct agent for tool execution
    tool_executor = create_react_agent(llm, tools)
    
    # Get task and context
    task_description = await safe_state.get("task_description", "")
    context = await safe_state.get("context", {})
    
    # Prepare prompt with context
    enhanced_prompt = f"""
    Task: {task_description}
    
    Available context:
    - Previous results: {await safe_state.get("results", {})}
    
    Instructions:
    1. Analyze what data is needed
    2. Use appropriate tools to gather data
    3. Synthesize insights from the data
    4. Provide actionable recommendations
    
    Available tools: {[tool.name for tool in tools]}
    """
    
    try:
        # Execute with tools
        result = await tool_executor.ainvoke({
            "messages": [HumanMessage(content=enhanced_prompt)]
        })
        
        # Extract tool usage and results
        tool_calls = []
        analysis_results = {}
        
        for message in result["messages"]:
            if hasattr(message, "tool_calls"):
                tool_calls.extend(message.tool_calls)
            if isinstance(message, ToolMessage):
                # Parse tool results
                try:
                    tool_result = json.loads(message.content)
                    analysis_results[message.name] = tool_result
                except:
                    analysis_results[message.name] = message.content
        
        # Update state safely
        await safe_state.update_results("analytics", {
            "timestamp": datetime.now().isoformat(),
            "analysis": result["messages"][-1].content if result["messages"] else "",
            "raw_data": analysis_results,
            "tool_calls": tool_calls,
            "status": "success"
        })
        
        return safe_state.to_dict()
        
    except Exception as e:
        logger.error(f"Error in analytics agent: {str(e)}")
        # Fallback handling
        return await handle_agent_error("analytics", e, safe_state)
```

### 1.2 Tool Nodeë¥¼ Graphì— í†µí•©

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**íŒŒì¼: `backend/src/core/graph.py` ìˆ˜ì •**

```python
from langgraph.prebuilt import ToolNode

def create_sales_support_graph(use_sqlite: bool = False):
    """Create graph with integrated tool nodes"""
    
    # Initialize StateGraph
    graph = StateGraph(AgentState)
    
    # Add agent nodes
    graph.add_node("supervisor", supervisor_agent)
    graph.add_node("analytics", analytics_agent_with_llm_tools)  # Updated
    graph.add_node("search", search_agent_with_llm_tools)  # Updated
    graph.add_node("document", document_agent_with_llm_tools)  # Updated
    graph.add_node("compliance", compliance_agent_with_llm_tools)  # Updated
    
    # Add tool nodes for each agent (optional - for explicit tool execution)
    graph.add_node("analytics_tools", ToolNode(analytics_tools))
    graph.add_node("search_tools", ToolNode(search_tools))
    
    # Add parallel executor
    graph.add_node("parallel_executor", parallel_executor)
    
    # Entry point
    graph.add_edge(START, "supervisor")
    
    # Smart routing with parallel execution
    graph.add_conditional_edges(
        "supervisor",
        determine_execution_path,
        {
            "parallel": "parallel_executor",
            "sequential": route_by_task_type,
            "end": END
        }
    )
    
    # Tool node connections (if needed)
    graph.add_conditional_edges(
        "analytics",
        lambda x: "analytics_tools" if x.get("needs_tools") else "supervisor"
    )
    
    # Optimized checkpointer
    checkpointer = create_optimized_checkpointer(use_sqlite)
    
    return graph.compile(checkpointer=checkpointer)
```

---

## ðŸš€ Phase 2: ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ [ë†’ìŒ]

### 2.1 ìž¬ì‹œë„ ì „ëžµ êµ¬í˜„

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**ìƒˆ íŒŒì¼: `backend/src/core/retry_strategy.py`**

```python
import asyncio
from typing import Callable, Dict, Any, Optional
from functools import wraps
from loguru import logger
from enum import Enum

class RetryPolicy(Enum):
    EXPONENTIAL = "exponential"
    LINEAR = "linear"
    FIBONACCI = "fibonacci"

class CircuitBreaker:
    """Circuit breaker pattern for agent protection"""
    
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failures = {}
        self.last_failure_time = {}
    
    def is_open(self, agent_name: str) -> bool:
        """Check if circuit is open (blocking requests)"""
        if agent_name not in self.failures:
            return False
        
        if self.failures[agent_name] >= self.failure_threshold:
            time_since_failure = time.time() - self.last_failure_time.get(agent_name, 0)
            if time_since_failure < self.timeout:
                return True
            else:
                # Reset after timeout
                self.reset(agent_name)
        return False
    
    def record_failure(self, agent_name: str):
        """Record a failure"""
        self.failures[agent_name] = self.failures.get(agent_name, 0) + 1
        self.last_failure_time[agent_name] = time.time()
    
    def record_success(self, agent_name: str):
        """Record a success and reset counter"""
        self.reset(agent_name)
    
    def reset(self, agent_name: str):
        """Reset circuit breaker for agent"""
        self.failures[agent_name] = 0
        self.last_failure_time.pop(agent_name, None)

# Global circuit breaker
circuit_breaker = CircuitBreaker()

class RetryStrategy:
    MAX_RETRIES = 3
    BASE_DELAY = 1  # seconds
    MAX_DELAY = 30  # seconds
    
    @staticmethod
    def calculate_delay(attempt: int, policy: RetryPolicy = RetryPolicy.EXPONENTIAL) -> float:
        """Calculate retry delay based on policy"""
        if policy == RetryPolicy.EXPONENTIAL:
            delay = min(RetryStrategy.BASE_DELAY * (2 ** attempt), RetryStrategy.MAX_DELAY)
        elif policy == RetryPolicy.LINEAR:
            delay = min(RetryStrategy.BASE_DELAY * attempt, RetryStrategy.MAX_DELAY)
        else:  # Fibonacci
            fib = [1, 1]
            for _ in range(attempt):
                fib.append(fib[-1] + fib[-2])
            delay = min(RetryStrategy.BASE_DELAY * fib[attempt], RetryStrategy.MAX_DELAY)
        
        # Add jitter to prevent thundering herd
        import random
        jitter = random.uniform(0, delay * 0.1)
        return delay + jitter
    
    @staticmethod
    def with_retry(agent_name: str, policy: RetryPolicy = RetryPolicy.EXPONENTIAL):
        """Decorator for retry logic"""
        def decorator(func: Callable):
            @wraps(func)
            async def wrapper(state: Dict[str, Any]) -> Dict[str, Any]:
                # Check circuit breaker
                if circuit_breaker.is_open(agent_name):
                    logger.warning(f"Circuit breaker open for {agent_name}")
                    return RetryStrategy.create_fallback_response(agent_name, "Circuit breaker open", state)
                
                last_error = None
                
                for attempt in range(RetryStrategy.MAX_RETRIES):
                    try:
                        result = await func(state)
                        circuit_breaker.record_success(agent_name)
                        return result
                        
                    except Exception as e:
                        last_error = e
                        logger.warning(f"Agent {agent_name} attempt {attempt + 1} failed: {str(e)}")
                        
                        if attempt < RetryStrategy.MAX_RETRIES - 1:
                            delay = RetryStrategy.calculate_delay(attempt, policy)
                            logger.info(f"Retrying {agent_name} in {delay:.2f} seconds...")
                            await asyncio.sleep(delay)
                        
                        # Record error in state
                        if "errors" not in state:
                            state["errors"] = []
                        state["errors"].append({
                            "agent": agent_name,
                            "error": str(e),
                            "attempt": attempt + 1,
                            "timestamp": datetime.now().isoformat()
                        })
                
                # All retries failed
                circuit_breaker.record_failure(agent_name)
                logger.error(f"Agent {agent_name} failed after {RetryStrategy.MAX_RETRIES} attempts")
                return RetryStrategy.create_fallback_response(agent_name, last_error, state)
            
            return wrapper
        return decorator
    
    @staticmethod
    def create_fallback_response(agent_name: str, error: Any, state: Dict[str, Any]) -> Dict[str, Any]:
        """Create fallback response for failed agent"""
        fallback_data = {
            "analytics": {
                "analysis": "Analysis temporarily unavailable - using cached data",
                "status": "fallback",
                "cached_data": state.get("context", {}).get("last_analytics", {})
            },
            "search": {
                "results": [],
                "status": "fallback",
                "message": "Search service temporarily unavailable"
            },
            "document": {
                "document": "Document generation failed - please retry",
                "status": "fallback"
            },
            "compliance": {
                "compliance_status": "PENDING",
                "status": "fallback",
                "message": "Compliance check pending - manual review required"
            }
        }
        
        # Update state with fallback
        if "results" not in state:
            state["results"] = {}
        state["results"][agent_name] = fallback_data.get(agent_name, {"status": "fallback"})
        
        # Mark as needing retry
        state["context"] = state.get("context", {})
        state["context"][f"{agent_name}_needs_retry"] = True
        state["context"][f"{agent_name}_fallback_used"] = True
        
        return state

# Apply retry decorator to all agents
@RetryStrategy.with_retry("analytics")
async def analytics_agent_with_retry(state: AgentState) -> dict:
    return await analytics_agent_with_llm_tools(state)
```

---

## ðŸš€ Phase 3: ë³‘ë ¬ ì‹¤í–‰ êµ¬í˜„ [ì¤‘ê°„]

### 3.1 ë¦¬ì†ŒìŠ¤ ì œí•œëœ ë³‘ë ¬ ì‹¤í–‰

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**íŒŒì¼: `backend/src/core/graph.py` ì¶”ê°€**

```python
import asyncio
from typing import List, Dict, Any

class ParallelExecutor:
    MAX_CONCURRENT = 3  # Resource limit
    
    def __init__(self, streaming_coordinator: StreamingCoordinator = None):
        self.coordinator = streaming_coordinator or StreamingCoordinator()
        self.semaphore = asyncio.Semaphore(self.MAX_CONCURRENT)
    
    async def execute_parallel_groups(self, state: AgentState) -> dict:
        """Execute agents in parallel groups with resource limits"""
        safe_state = ThreadSafeState(state)
        
        # Get execution plan
        parallel_groups = state.get("context", {}).get("parallel_groups", [])
        
        if not parallel_groups:
            logger.warning("No parallel groups defined")
            return state
        
        # Process each group
        for group_idx, group in enumerate(parallel_groups):
            logger.info(f"Executing parallel group {group_idx}: {group}")
            
            # Create tasks with resource limits
            tasks = []
            for agent_name in group:
                agent_func = self._get_agent_function(agent_name)
                if agent_func:
                    # Wrap with semaphore for resource limiting
                    task = self._execute_with_limit(agent_func, safe_state, agent_name)
                    tasks.append(task)
            
            # Execute with partial failure handling
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            for i, result in enumerate(results):
                agent_name = group[i]
                
                if isinstance(result, Exception):
                    logger.error(f"Agent {agent_name} failed in parallel execution: {result}")
                    # Use fallback
                    fallback_state = RetryStrategy.create_fallback_response(
                        agent_name, result, safe_state.to_dict()
                    )
                    await safe_state.update_results(agent_name, 
                        fallback_state["results"].get(agent_name, {}))
                else:
                    # Success - merge results
                    if isinstance(result, dict) and "results" in result:
                        agent_results = result["results"].get(agent_name, {})
                        await safe_state.update_results(agent_name, agent_results)
            
            # Update progress
            state["context"]["completed_groups"] = group_idx + 1
        
        return safe_state.to_dict()
    
    async def _execute_with_limit(self, agent_func, safe_state, agent_name):
        """Execute agent with resource limits"""
        async with self.semaphore:
            logger.info(f"Starting {agent_name} (semaphore acquired)")
            
            # Monitor memory usage
            import psutil
            process = psutil.Process()
            mem_before = process.memory_info().rss / 1024 / 1024  # MB
            
            try:
                result = await agent_func(safe_state.to_dict())
                
                mem_after = process.memory_info().rss / 1024 / 1024  # MB
                mem_increase = mem_after - mem_before
                
                if mem_increase > 100:  # Warning if >100MB increase
                    logger.warning(f"Agent {agent_name} increased memory by {mem_increase:.2f}MB")
                
                return result
                
            finally:
                logger.info(f"Completed {agent_name} (semaphore released)")
    
    def _get_agent_function(self, agent_name: str):
        """Get agent function by name"""
        agents = {
            "analytics": analytics_agent_with_retry,
            "search": search_agent_with_retry,
            "document": document_agent_with_retry,
            "compliance": compliance_agent_with_retry
        }
        return agents.get(agent_name)

# Create global parallel executor
parallel_executor_instance = ParallelExecutor()

async def parallel_executor(state: AgentState) -> dict:
    """Parallel executor node for graph"""
    return await parallel_executor_instance.execute_parallel_groups(state)
```

### 3.2 ì˜ì¡´ì„± ë¶„ì„ ë° ê·¸ë£¹í™”

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**íŒŒì¼: `backend/src/agents/supervisor.py` ìˆ˜ì •**

```python
def analyze_task_dependencies(user_request: str, agents_needed: List[str]) -> Dict[str, List[str]]:
    """Analyze dependencies between agents"""
    # Define static dependencies
    dependencies = {
        "analytics": [],  # Can run independently
        "search": [],     # Can run independently
        "document": [],   # Now can run independently with fallback
        "compliance": ["document"]  # Must run after document
    }
    
    # Dynamic dependency injection based on request
    request_lower = user_request.lower()
    
    # If document generation needs data, add dependencies
    if "document" in agents_needed:
        if "ë¶„ì„" in request_lower or "analysis" in request_lower:
            dependencies["document"].append("analytics")
        if "ê²€ìƒ‰" in request_lower or "search" in request_lower:
            dependencies["document"].append("search")
    
    return dependencies

def create_parallel_groups(agents: List[str], dependencies: Dict[str, List[str]]) -> List[List[str]]:
    """Create optimal parallel execution groups"""
    groups = []
    completed = set()
    remaining = set(agents)
    
    while remaining:
        current_group = []
        
        for agent in remaining:
            agent_deps = dependencies.get(agent, [])
            # Can execute if all dependencies are completed
            if all(dep in completed for dep in agent_deps):
                current_group.append(agent)
        
        if not current_group:
            # Circular dependency or error
            logger.error(f"Cannot resolve dependencies for agents: {remaining}")
            current_group = list(remaining)  # Force execution
        
        groups.append(current_group)
        completed.update(current_group)
        remaining -= set(current_group)
    
    return groups

# Update supervisor_agent function
def supervisor_agent(state: AgentState) -> dict:
    """Enhanced supervisor with parallel execution planning"""
    # ... existing code ...
    
    # After determining agents needed
    planned_agents = execution_plan.get("agents", ["analytics"])
    
    # Analyze dependencies
    dependencies = analyze_task_dependencies(user_request, planned_agents)
    
    # Create parallel groups
    parallel_groups = create_parallel_groups(planned_agents, dependencies)
    
    # Determine execution mode
    execution_mode = "parallel" if len(parallel_groups[0]) > 1 else "sequential"
    
    updated_context = {
        **context,
        "execution_plan": planned_agents,
        "dependencies": dependencies,
        "parallel_groups": parallel_groups,
        "execution_mode": execution_mode,
        "current_group": 0
    }
    
    # Route to parallel executor if needed
    if execution_mode == "parallel":
        return {
            **state,
            "context": updated_context,
            "next_node": "parallel_executor"
        }
    
    # ... rest of existing code ...
```

---

## ðŸš€ Phase 4: ë¼ìš°íŒ… ìµœì í™” [ì¤‘ê°„]

### 4.1 ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… êµ¬í˜„

#### âœ… êµ¬í˜„ ì§€ì‹œì‚¬í•­

**íŒŒì¼: `backend/src/core/graph.py` ìˆ˜ì •**

```python
def create_smart_router():
    """Create intelligent routing function"""
    
    def smart_route(state: AgentState) -> str:
        current_agent = state.get("current_agent")
        context = state.get("context", {})
        results = state.get("results", {})
        errors = state.get("errors", [])
        
        # Check for critical errors
        recent_errors = [e for e in errors if e.get("agent") == current_agent]
        if len(recent_errors) >= 3:
            logger.error(f"Agent {current_agent} failed multiple times, ending")
            return END
        
        # Parallel execution mode
        if context.get("execution_mode") == "parallel":
            current_group = context.get("current_group", 0)
            parallel_groups = context.get("parallel_groups", [])
            
            if current_group < len(parallel_groups) - 1:
                return "parallel_executor"
        
        # Direct routing rules
        routing_rules = {
            ("document", "requires_compliance"): "compliance",
            ("compliance", "needs_rework"): lambda: context.get("rework_target", "document"),
            ("analytics", "search_needed"): "search",
            ("search", "document_ready"): "document"
        }
        
        for (agent, condition), target in routing_rules.items():
            if current_agent == agent and context.get(condition):
                if callable(target):
                    return target()
                return target
        
        # Check if all planned agents completed
        execution_plan = context.get("execution_plan", [])
        completed_agents = list(results.keys())
        
        if all(agent in completed_agents for agent in execution_plan):
            return END
        
        # Default to supervisor for coordination
        return "supervisor"
    
    return smart_route

# Apply to graph
smart_router = create_smart_router()

graph.add_conditional_edges("analytics", smart_router)
graph.add_conditional_edges("search", smart_router)
graph.add_conditional_edges("document", smart_router)
graph.add_conditional_edges("compliance", smart_router)
graph.add_conditional_edges("parallel_executor", smart_router)
```

---

## ðŸ“ êµ¬í˜„ ìš°ì„ ìˆœìœ„ ë° ì¼ì •

### ìš°ì„ ìˆœìœ„ë³„ êµ¬í˜„ ê³„íš

1. **Phase 0**: ê¸°ì´ˆ ì•ˆì „ìž¥ì¹˜ [1ì‹œê°„]
   - ThreadSafeState êµ¬í˜„
   - Checkpointer ìµœì í™”
   - StreamingCoordinator êµ¬í˜„

2. **Phase 1-2**: Tool ì‹¤í–‰ + ì—ëŸ¬ ë³µêµ¬ [3ì‹œê°„]
   - LLM ê¸°ë°˜ tool ì‹¤í–‰
   - RetryStrategy êµ¬í˜„
   - CircuitBreaker íŒ¨í„´

3. **Phase 3-4**: ë³‘ë ¬ ì‹¤í–‰ + ë¼ìš°íŒ… [2.5ì‹œê°„]
   - ParallelExecutor êµ¬í˜„
   - ì˜ì¡´ì„± ë¶„ì„
   - Smart routing

4. **í…ŒìŠ¤íŠ¸ ë° ê²€ì¦**: [1.5ì‹œê°„]
   - í†µí•© í…ŒìŠ¤íŠ¸
   - ì„±ëŠ¥ ì¸¡ì •
   - ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§

**ì´ ì˜ˆìƒ ì‹œê°„: 8ì‹œê°„**

## ðŸŽ¯ ì„±ê³µ ì§€í‘œ

### í•„ìˆ˜ ë‹¬ì„± ëª©í‘œ
- âœ… ë™ì‹œì„± ì•ˆì „ì„± 100%
- âœ… ë¶€ë¶„ ì‹¤íŒ¨ ì‹œì—ë„ ì„œë¹„ìŠ¤ ì§€ì†
- âœ… WebSocket ë©”ì‹œì§€ ìˆœì„œ ë³´ìž¥
- âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ < 30%

### ì„±ëŠ¥ ëª©í‘œ
- ðŸ“ˆ ì‘ë‹µ ì‹œê°„ 30-40% ë‹¨ì¶• (ë³‘ë ¬ ì‹¤í–‰)
- ðŸ“ˆ ê°€ìš©ì„± 95% ì´ìƒ (ì—ëŸ¬ ë³µêµ¬)
- ðŸ“ˆ Tool ì‹¤í–‰ ì •í™•ë„ 90% ì´ìƒ

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í•„ìˆ˜**
   - ë³‘ë ¬ ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
   - OOM ë°©ì§€ë¥¼ ìœ„í•œ ì œí•œ ì„¤ì •

2. **WebSocket í´ë¼ì´ì–¸íŠ¸ ìˆ˜ì • í•„ìš”**
   - ë³‘ë ¬ ë©”ì‹œì§€ ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
   - ìˆœì„œ ìž¬ì •ë ¬ ê°€ëŠ¥ì„± ëŒ€ë¹„

3. **ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ ê³ ë ¤**
   - SQLite WAL ëª¨ë“œ í•„ìˆ˜
   - í•„ìš”ì‹œ Redis ì „í™˜ ê²€í† 

4. **ë¡œê¹… ë ˆë²¨ ì¡°ì •**
   - Production: INFO ë ˆë²¨
   - ë””ë²„ê¹…: DEBUG ë ˆë²¨ (ì„±ëŠ¥ ì˜í–¥ ì£¼ì˜)

## ðŸ“ íŒŒì¼ ë³€ê²½ ìš”ì•½

### ì‹ ê·œ íŒŒì¼ (5ê°œ)
- `backend/src/core/concurrency.py` - Thread ì•ˆì „ì„±
- `backend/src/core/streaming.py` - ìŠ¤íŠ¸ë¦¬ë° ì¡°ì •
- `backend/src/core/retry_strategy.py` - ìž¬ì‹œë„ ì „ëžµ
- `backend/src/core/monitoring.py` - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- `backend/tests/test_parallel_execution.py` - ë³‘ë ¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸

### ìˆ˜ì • íŒŒì¼ (7ê°œ)
- `backend/src/agents/analytics.py` - LLM tool ì‹¤í–‰
- `backend/src/agents/search.py` - LLM tool ì‹¤í–‰
- `backend/src/agents/document.py` - LLM tool ì‹¤í–‰
- `backend/src/agents/compliance.py` - LLM tool ì‹¤í–‰
- `backend/src/agents/supervisor.py` - ë³‘ë ¬ ê³„íš ìˆ˜ë¦½
- `backend/src/core/graph.py` - ë³‘ë ¬ ì‹¤í–‰, ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…
- `backend/src/api/app.py` - WebSocket ìŠ¤íŠ¸ë¦¬ë° ì¡°ì •